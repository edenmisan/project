{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6cad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadar\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\hadar\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Core\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Visualization\n",
    "# =========================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =========================\n",
    "# Scikit-learn – preprocessing\n",
    "# =========================\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# =========================\n",
    "# Scikit-learn – model selection\n",
    "# =========================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =========================\n",
    "# Scikit-learn – models\n",
    "# =========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# =========================\n",
    "# Scikit-learn – evaluation metrics\n",
    "# =========================\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve)\n",
    "\n",
    "# =========================\n",
    "# GPU (RAPIDS – optional)\n",
    "# =========================\n",
    "USE_GPU = True\n",
    "try:\n",
    "    import cudf\n",
    "    from cuml.svm import SVC as cuSVC\n",
    "    from cuml.metrics import roc_auc_score as cuml_roc_auc_score\n",
    "except Exception as e:\n",
    "    USE_GPU = False\n",
    "    gpu_import_error = repr(e)\n",
    "\n",
    "# טעינת הדאטה\n",
    "file_path = r\"C:\\Users\\hadar\\Downloads\\Traffic_Crashes_-_Crashes.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbae90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# רשימת עמודות למחיקה\n",
    "columns_to_drop = [\n",
    "    'CRASH_RECORD_ID',\n",
    "    'CRASH_DATE_EST_I',\n",
    "    'LANE_CNT',\n",
    "    'REPORT_TYPE',\n",
    "    'INTERSECTION_RELATED_I',\n",
    "    'NOT_RIGHT_OF_WAY_I',\n",
    "    'HIT_AND_RUN_I',\n",
    "    'DOORING_I',\n",
    "    'PHOTOS_TAKEN_I',\n",
    "    'STATEMENTS_TAKEN_I',\n",
    "    'WORK_ZONE_I',\n",
    "    'WORK_ZONE_TYPE',\n",
    "    'WORKERS_PRESENT_I',\n",
    "    'DATE_POLICE_NOTIFIED',\n",
    "    'SEC_CONTRIBUTORY_CAUSE',\n",
    "    'STREET_DIRECTION',\n",
    "    'STREET_NO',\n",
    "    'STREET_NAME',\n",
    "    'BEAT_OF_OCCURRENCE',\n",
    "    'INJURIES_TOTAL',\n",
    "    'INJURIES_FATAL',\n",
    "    'INJURIES_INCAPACITATING',\n",
    "    'INJURIES_NON_INCAPACITATING',\n",
    "    'INJURIES_REPORTED_NOT_EVIDENT',\n",
    "    'INJURIES_NO_INDICATION',\n",
    "    'INJURIES_UNKNOWN',\n",
    "    'LOCATION',\n",
    "    'LATITUDE',\n",
    "    'LONGITUDE',\n",
    "    'CRASH_TYPE'\n",
    "]\n",
    "\n",
    "# מחיקת העמודות\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4e683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# המרת עמודת התאריך לפורמט datetime\n",
    "df['CRASH_DATE'] = pd.to_datetime(df['CRASH_DATE'])\n",
    "\n",
    "# יצירת עמודת זמן (שעה בלבד)\n",
    "df['CRASH_TIME'] = df['CRASH_DATE'].dt.time\n",
    "\n",
    "# יצירת עמודת חודש\n",
    "df['CRASH_MONTH'] = df['CRASH_DATE'].dt.month\n",
    "\n",
    "# יצירת עמודת שנה\n",
    "df['CRASH_YEAR'] = df['CRASH_DATE'].dt.year\n",
    "\n",
    "# יצירת עמודת יום בשבוע\n",
    "# pandas: Monday=0 ... Sunday=6\n",
    "# אנחנו רוצים: Sunday=1 ... Saturday=7\n",
    "df['CRASH_DAY_OF_WEEK'] = df['CRASH_DATE'].dt.weekday\n",
    "df['CRASH_DAY_OF_WEEK'] = ((df['CRASH_DAY_OF_WEEK'] + 1) % 7) + 1\n",
    "df = df[df['CRASH_YEAR'] == 2025].copy()\n",
    "df = df.drop(columns=['CRASH_DATE','CRASH_YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bcb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# אם CRASH_TIME הוא datetime.time / או מחרוזת - נהפוך אותו לטיפוס זמן אחיד\n",
    "# (אם כבר אצלך הוא time, זה פשוט יעבוד)\n",
    "crash_time = pd.to_datetime(df['CRASH_TIME'].astype(str), format='%H:%M:%S', errors='coerce')\n",
    "\n",
    "# דקות מאז חצות (שומר דיוק: שעה+דקות+שניות)\n",
    "df['CRASH_MINUTES_FROM_MIDNIGHT'] = crash_time.dt.hour * 60 + crash_time.dt.minute + (crash_time.dt.second / 60)\n",
    "\n",
    "# IS_NIGHT: בין 20:00–06:00\n",
    "# 20:00 = 1200 דקות, 06:00 = 360 דקות\n",
    "df['IS_NIGHT'] = df['CRASH_MINUTES_FROM_MIDNIGHT'].apply(\n",
    "    lambda m: 1 if (m >= 1200 or m < 360) else 0)\n",
    "\n",
    "# IS_WEEKEND: יום ראשון (1) או שבת (7)\n",
    "df['IS_WEEKEND'] = df['CRASH_DAY_OF_WEEK'].apply(lambda d: 1 if d in [1, 7] else 0)\n",
    "\n",
    "# IS_RUSH_HOUR: 7–9 כולל ו־16–18 כולל\n",
    "df['IS_RUSH_HOUR'] = df['CRASH_MINUTES_FROM_MIDNIGHT'].apply(\n",
    "    lambda m: 1 if (420 <= m <= 540 or 960 <= m <= 1080) else 0)\n",
    "\n",
    "df = df.drop(columns=['CRASH_MINUTES_FROM_MIDNIGHT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab0cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# המהירות החוקית הנמוכה ביותר בשיקגו היא 15 mph (סמטאות),\n",
    "# לכן ערכים נמוכים מ-15 אינם מייצגים תמרור חוקי ונחשבים שגויים\n",
    "df['POSTED_SPEED_LIMIT'] = pd.to_numeric(df['POSTED_SPEED_LIMIT'], errors='coerce')\n",
    "\n",
    "# להשאיר רק שורות עם מהירות >= 15 או ערך חסר (NaN)\n",
    "df = df[df['POSTED_SPEED_LIMIT'].isna() | (df['POSTED_SPEED_LIMIT'] >= 15)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4215388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'TRAFFIC_CONTROL_DEVICE'\n",
    "threshold = 5000\n",
    "\n",
    "# 1) איחוד UNKNOWN ו-NaN ל-OTHER\n",
    "df[col] = df[col].fillna('OTHER').replace('UNKNOWN', 'OTHER')\n",
    "\n",
    "KEEP = {\n",
    "    \"NO CONTROLS\",\n",
    "    \"TRAFFIC SIGNAL\",\n",
    "    \"STOP SIGN/FLASHER\"}\n",
    "df = df[df[\"TRAFFIC_CONTROL_DEVICE\"].isin(KEEP)].copy()\n",
    "\n",
    "df = df[df[col] != 'OTHER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081e9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'DEVICE_CONDITION'\n",
    "\n",
    "# ניקוי רווחים ויישור טקסט\n",
    "df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# 1) איחוד UNKNOWN עם OTHER (וגם NaN אם יש)\n",
    "df[col] = df[col].replace({'UNKNOWN': 'OTHER'}).fillna('OTHER')\n",
    "\n",
    "# 2) איחוד קטגוריות \"לא מתפקד\" לקטגוריה אחת\n",
    "df[col] = df[col].replace({\n",
    "    'FUNCTIONING IMPROPERLY': 'NOT_FUNCTIONING',\n",
    "    'NOT FUNCTIONING': 'NOT_FUNCTIONING',\n",
    "    'WORN REFLECTIVE MATERIAL': 'NOT_FUNCTIONING',\n",
    "    'MISSING': 'NOT_FUNCTIONING'\n",
    "})\n",
    "\n",
    "# 3) הסרת שורות עם OTHER (כולל UNKNOWN שאוחד)\n",
    "df = df[df[col] != 'OTHER'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbbb4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'WEATHER_CONDITION'\n",
    "\n",
    "# 1) ניקוי רווחים\n",
    "df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# 2) הסרת UNKNOWN / OTHER / NaN\n",
    "df[col] = df[col].replace(['UNKNOWN', 'OTHER'], 'UNKNOWN').fillna('UNKNOWN')\n",
    "df = df[df[col] != 'UNKNOWN'].copy()\n",
    "\n",
    "# 3) איחוד קטגוריות בתוך אותה עמודה\n",
    "df.loc[df[col] == 'CLEAR', col] = 'Clear'\n",
    "df.loc[df[col] == 'CLOUDY/OVERCAST', col] = 'Cloudy'\n",
    "df.loc[df[col] == 'RAIN', col] = 'Rain'\n",
    "\n",
    "df.loc[df[col].isin([\n",
    "    'SNOW',\n",
    "    'SLEET/HAIL',\n",
    "    'FREEZING RAIN/DRIZZLE',\n",
    "    'BLOWING SNOW'\n",
    "]), col] = 'Snow/Ice'\n",
    "\n",
    "df.loc[df[col].isin([\n",
    "    'FOG/SMOKE/HAZE',\n",
    "    'SEVERE CROSS WIND GATE',\n",
    "    'BLOWING SAND, SOIL, DIRT'\n",
    "]), col] = 'Low Visibility'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56600ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ניקוי רווחים\n",
    "df['LIGHTING_CONDITION'] = df['LIGHTING_CONDITION'].astype(str).str.strip()\n",
    "\n",
    "# הסרת UNKNOWN\n",
    "df = df[df['LIGHTING_CONDITION'] != 'UNKNOWN'].copy()\n",
    "\n",
    "# איחוד קטגוריות: DAWN + DUSK -> TWILIGHT\n",
    "df['LIGHTING_CONDITION'] = df['LIGHTING_CONDITION'].replace({\n",
    "    'DAWN': 'TWILIGHT',\n",
    "    'DUSK': 'TWILIGHT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de2b0867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['TRAFFICWAY_TYPE'].isin([\n",
    "    'OTHER',\n",
    "    'UNKNOWN',\n",
    "    'NOT REPORTED',\n",
    "    'UNKNOWN INTERSECTION TYPE'\n",
    "])].copy()\n",
    "df = df[~df['ROADWAY_SURFACE_COND'].isin(['OTHER', 'UNKNOWN'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73df2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'ROAD_DEFECT'\n",
    "\n",
    "# 1) ניקוי רווחים\n",
    "df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# 2) הסרת UNKNOWN ו-OTHER\n",
    "df = df[~df[col].isin(['UNKNOWN', 'OTHER'])].copy()\n",
    "\n",
    "# 3) המרה לבינארי:\n",
    "# NO DEFECTS -> 0\n",
    "# כל סוג פגם אחר -> 1\n",
    "df[col] = df[col].apply(\n",
    "    lambda x: 0 if x == 'NO DEFECTS' else 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b266f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['PRIM_CONTRIBUTORY_CAUSE'].isin([\n",
    "    'UNABLE TO DETERMINE',\n",
    "    'NOT APPLICABLE'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3b82119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# יצירת משתנה יעד בינארי: פגיעה / ללא פגיעה\n",
    "df['INJURY'] = df['MOST_SEVERE_INJURY'].apply(\n",
    "    lambda x: 0 if x == 'NO INDICATION OF INJURY' else 1\n",
    ").astype(int)\n",
    "\n",
    "# (אופציונלי ומומלץ) הסרת עמודת המקור\n",
    "df = df.drop(columns=['MOST_SEVERE_INJURY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab88582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# המרה ל-datetime אם צריך\n",
    "df['CRASH_TIME'] = pd.to_datetime(df['CRASH_TIME'], format='%H:%M:%S')\n",
    "\n",
    "# דקות מאז חצות\n",
    "df['CRASH_MINUTES_FROM_MIDNIGHT'] = (\n",
    "    df['CRASH_TIME'].dt.hour * 60 +\n",
    "    df['CRASH_TIME'].dt.minute)\n",
    "df = df.drop(columns=['CRASH_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01ff125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CRASH_TIME_SIN'] = np.sin(2 * np.pi * df['CRASH_MINUTES_FROM_MIDNIGHT'] / 1440)\n",
    "df['CRASH_TIME_COS'] = np.cos(2 * np.pi * df['CRASH_MINUTES_FROM_MIDNIGHT'] / 1440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e74fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0) עזר: לנקות טקסטים בעמודות קטגוריות (מונע רווחים/None)\n",
    "# ------------------------------------------------------------\n",
    "cat_cols_for_rules = [\n",
    "    'TRAFFIC_CONTROL_DEVICE',\n",
    "    'LIGHTING_CONDITION',\n",
    "    'WEATHER_CONDITION'\n",
    "]\n",
    "\n",
    "for c in cat_cols_for_rules:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) NIGHT + NO TRAFFIC CONTROL\n",
    "#    (IS_NIGHT = 1 וגם TRAFFIC_CONTROL_DEVICE == 'NO CONTROLS')\n",
    "# ------------------------------------------------------------\n",
    "df['NIGHT_AND_NO_CONTROL'] = (\n",
    "    (df['IS_NIGHT'] == 1) &\n",
    "    (df['TRAFFIC_CONTROL_DEVICE'].eq('NO CONTROLS'))\n",
    ").astype(int)\n",
    "\n",
    "# למה כדאי? בלילה בלי בקרה תנועתית יש פחות \"הכוונה\" → עלול להגדיל פגיעות.\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) NIGHT + POOR LIGHTING\n",
    "#    (לילה + DARKNESS)\n",
    "# ------------------------------------------------------------\n",
    "df['NIGHT_AND_POOR_LIGHTING'] = (\n",
    "    (df['IS_NIGHT'] == 1) &\n",
    "    (df['LIGHTING_CONDITION'].eq('DARKNESS'))\n",
    ").astype(int)\n",
    "\n",
    "# למה כדאי? שילוב חושך ותאורה לקויה מצמצם ראות וזמן תגובה.\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) RUSH HOUR + NO TRAFFIC CONTROL\n",
    "# ------------------------------------------------------------\n",
    "df['RUSH_AND_NO_CONTROL'] = (\n",
    "    (df['IS_RUSH_HOUR'] == 1) &\n",
    "    (df['TRAFFIC_CONTROL_DEVICE'].eq('NO CONTROLS'))\n",
    ").astype(int)\n",
    "\n",
    "# למה כדאי? עומס תנועה ללא ויסות מעלה קונפליקטים וסיכון לתאונות.\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) WEEKEND + NIGHT\n",
    "# ------------------------------------------------------------\n",
    "df['WEEKEND_NIGHT'] = (\n",
    "    (df['IS_WEEKEND'] == 1) &\n",
    "    (df['IS_NIGHT'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# למה כדאי? שעות בילוי/עייפות בסופ\"ש בלילה קשורות לעיתים לסיכון מוגבר.\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) MULTI_VEHICLE (יותר מרכב אחד)\n",
    "# ------------------------------------------------------------\n",
    "if 'NUM_UNITS' in df.columns:\n",
    "    df['MULTI_VEHICLE_3PLUS'] = (df['NUM_UNITS'] >= 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b25055",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['INJURY']\n",
    "X = df.drop(columns=['INJURY'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c3d5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [\n",
    "    'TRAFFIC_CONTROL_DEVICE',\n",
    "    'DEVICE_CONDITION',\n",
    "    'WEATHER_CONDITION',\n",
    "    'LIGHTING_CONDITION',\n",
    "    'FIRST_CRASH_TYPE',\n",
    "    'TRAFFICWAY_TYPE',\n",
    "    'ALIGNMENT',\n",
    "    'ROADWAY_SURFACE_COND',\n",
    "    'DAMAGE',\n",
    "    'PRIM_CONTRIBUTORY_CAUSE'\n",
    "]\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    handle_unknown='ignore',\n",
    "    sparse_output=False)\n",
    "\n",
    "# fit רק על TRAIN\n",
    "train_ohe = ohe.fit_transform(X_train[ohe_cols])\n",
    "\n",
    "# transform על TEST\n",
    "test_ohe = ohe.transform(X_test[ohe_cols])\n",
    "\n",
    "new_cols = ohe.get_feature_names_out(ohe_cols)\n",
    "\n",
    "train_ohe_df = pd.DataFrame(train_ohe, columns=new_cols, index=X_train.index).astype(int)\n",
    "test_ohe_df  = pd.DataFrame(test_ohe,  columns=new_cols, index=X_test.index).astype(int)\n",
    "\n",
    "# הסרת עמודות מקוריות וחיבור החדשות\n",
    "X_train = pd.concat(\n",
    "    [X_train.drop(columns=ohe_cols), train_ohe_df],\n",
    "    axis=1\n",
    ")\n",
    "X_test = pd.concat(\n",
    "    [X_test.drop(columns=ohe_cols), test_ohe_df],\n",
    "    axis=1)\n",
    "\n",
    "num_cols = [\n",
    "    'POSTED_SPEED_LIMIT',\n",
    "    'NUM_UNITS',\n",
    "    'CRASH_TIME_SIN',\n",
    "    'CRASH_TIME_COS',\n",
    "    'CRASH_MINUTES_FROM_MIDNIGHT'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit רק על TRAIN\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "# transform על TEST\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf30a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INJURY\n",
      "0    0.790229\n",
      "1    0.209771\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9324672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "MODEL: Logistic Regression (Recall>=0.75, max Precision)\n",
      "======================================================\n",
      "Chosen threshold:        0.455637\n",
      "Precision at threshold:  0.370\n",
      "Recall at threshold:     0.750\n",
      "ROC-AUC:                 0.7917\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     0.662     0.766      8594\n",
      "           1      0.370     0.750     0.496      2281\n",
      "\n",
      "    accuracy                          0.680     10875\n",
      "   macro avg      0.640     0.706     0.631     10875\n",
      "weighted avg      0.796     0.680     0.709     10875\n",
      "\n",
      "Confusion matrix:\n",
      "[[5685 2909]\n",
      " [ 570 1711]]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Logistic Regression (Threshold tuned for Recall >= 0.75)\n",
    "# ============================================================\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "# =========================\n",
    "# 1) Predict probabilities\n",
    "# =========================\n",
    "y_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =========================\n",
    "# 2) ROC-AUC (threshold independent)\n",
    "# =========================\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# =========================\n",
    "# 3) Precision–Recall curve\n",
    "# =========================\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Align arrays: thr length = len(prec)-1 = len(rec)-1\n",
    "prec_thr = prec[1:]\n",
    "rec_thr  = rec[1:]\n",
    "\n",
    "# =========================\n",
    "# 4) Choose Threshold:\n",
    "#    minimum recall 0.75 + maximize precision\n",
    "# =========================\n",
    "target_recall = 0.75\n",
    "valid = np.where(rec_thr >= target_recall)[0]\n",
    "\n",
    "print(\"======================================================\")\n",
    "print(\"MODEL: Logistic Regression (Recall>=0.75, max Precision)\")\n",
    "print(\"======================================================\")\n",
    "\n",
    "if len(valid) == 0:\n",
    "    print(f\"No threshold achieves recall >= {target_recall}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "else:\n",
    "    best_idx = valid[np.argmax(prec_thr[valid])]\n",
    "    best_thr = thr[best_idx]\n",
    "\n",
    "    y_pred = (y_proba >= best_thr).astype(int)\n",
    "\n",
    "    print(f\"Chosen threshold:        {best_thr:.6f}\")\n",
    "    print(f\"Precision at threshold:  {prec_thr[best_idx]:.3f}\")\n",
    "    print(f\"Recall at threshold:     {rec_thr[best_idx]:.3f}\")\n",
    "    print(f\"ROC-AUC:                 {roc_auc:.4f}\\n\")\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d80589f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "MODEL: Random Forest (Recall>=0.75, max Precision)\n",
      "===============================================\n",
      "Chosen threshold: 0.469674\n",
      "Precision at threshold: 0.369\n",
      "Recall at threshold:    0.751\n",
      "ROC-AUC:                0.7894\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     0.659     0.764      8594\n",
      "           1      0.369     0.751     0.495      2281\n",
      "\n",
      "    accuracy                          0.679     10875\n",
      "   macro avg      0.639     0.705     0.630     10875\n",
      "weighted avg      0.796     0.679     0.708     10875\n",
      "\n",
      "Confusion matrix:\n",
      "[[5667 2927]\n",
      " [ 569 1712]]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Random Forest Classifier (Threshold tuned for Recall >= 0.75)\n",
    "# ============================================================\n",
    "\n",
    "# =========================\n",
    "# 1) Build the model\n",
    "# =========================\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) Train\n",
    "# =========================\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# =========================\n",
    "# 3) Predict probabilities\n",
    "# =========================\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =========================\n",
    "# 4) ROC-AUC (threshold independent)\n",
    "# =========================\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# =========================\n",
    "# 5) Precision–Recall Curve\n",
    "# =========================\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# thr is shorter by 1, align accordingly\n",
    "prec_thr = prec[1:]\n",
    "rec_thr  = rec[1:]\n",
    "\n",
    "# =========================\n",
    "# 6) Choose Threshold:\n",
    "#    minimum recall 0.75 + maximize precision\n",
    "# =========================\n",
    "target_recall = 0.75\n",
    "valid = np.where(rec_thr >= target_recall)[0]\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"MODEL: Random Forest (Recall>=0.75, max Precision)\")\n",
    "print(\"===============================================\")\n",
    "\n",
    "if len(valid) == 0:\n",
    "    print(f\"No threshold achieves recall >= {target_recall}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "else:\n",
    "    best_idx = valid[np.argmax(prec_thr[valid])]\n",
    "    best_thr = thr[best_idx]\n",
    "\n",
    "    y_pred = (y_proba >= best_thr).astype(int)\n",
    "\n",
    "    # metrics at chosen threshold\n",
    "    chosen_precision = prec_thr[best_idx]\n",
    "    chosen_recall    = rec_thr[best_idx]\n",
    "\n",
    "    # =========================\n",
    "    # 7) Results\n",
    "    # =========================\n",
    "    print(f\"Chosen threshold: {best_thr:.6f}\")\n",
    "    print(f\"Precision at threshold: {chosen_precision:.3f}\")\n",
    "    print(f\"Recall at threshold:    {chosen_recall:.3f}\")\n",
    "    print(f\"ROC-AUC:                {roc_auc:.4f}\\n\")\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c17bf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "SVM (sklearn / CPU) – GPU not available\n",
      "==============================\n",
      "Reason: NameError(\"name 'cudf' is not defined\")\n",
      "Tip: To use GPU you must install RAPIDS (cudf/cuml) with a CUDA-matching environment.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79      8594\n",
      "           1       0.38      0.71      0.50      2281\n",
      "\n",
      "    accuracy                           0.70     10875\n",
      "   macro avg       0.64      0.70      0.64     10875\n",
      "weighted avg       0.79      0.70      0.73     10875\n",
      "\n",
      "ROC-AUC (score): 0.7789\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper: convert inputs safely to numpy (for CPU fallback)\n",
    "# ============================================================\n",
    "def to_numpy(X):\n",
    "    # pandas\n",
    "    if hasattr(X, \"to_numpy\"):\n",
    "        return X.to_numpy()\n",
    "    return np.asarray(X)\n",
    "\n",
    "# ============================================================\n",
    "# Try GPU (RAPIDS) - fallback to CPU if not available\n",
    "# ============================================================\n",
    "USE_GPU = True\n",
    "try:\n",
    "    _ = cudf\n",
    "    _ = cuSVC\n",
    "    _ = cuml_roc_auc_score\n",
    "except Exception as e:\n",
    "    USE_GPU = False\n",
    "    gpu_import_error = repr(e)\n",
    "\n",
    "# ============================================================\n",
    "# 1) Expect you already have:\n",
    "#    X_train, X_test, y_train, y_test\n",
    "# ============================================================\n",
    "\n",
    "if USE_GPU:\n",
    "    # -------------------------\n",
    "    # GPU path (cuML)\n",
    "    # -------------------------\n",
    "    def to_cudf(X):\n",
    "        \"\"\"\n",
    "        Convert pandas DataFrame / numpy array -> cuDF DataFrame.\n",
    "        If X is sparse, convert to dense (may be heavy).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if sp.issparse(X):\n",
    "                X = X.toarray()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if hasattr(X, \"to_numpy\"):  # pandas\n",
    "            return cudf.DataFrame.from_pandas(X)\n",
    "        return cudf.DataFrame(X)\n",
    "\n",
    "    def to_cudf_series(y):\n",
    "        if hasattr(y, \"to_numpy\"):\n",
    "            y = y.to_numpy()\n",
    "        return cudf.Series(y)\n",
    "\n",
    "    # Move to GPU\n",
    "    X_train_gpu = to_cudf(X_train)\n",
    "    X_test_gpu  = to_cudf(X_test)\n",
    "    y_train_gpu = to_cudf_series(y_train)\n",
    "    y_test_gpu  = to_cudf_series(y_test)\n",
    "\n",
    "    # Ensure float32 to reduce memory\n",
    "    for col in X_train_gpu.columns:\n",
    "        if X_train_gpu[col].dtype == np.float64:\n",
    "            X_train_gpu[col] = X_train_gpu[col].astype(np.float32)\n",
    "            X_test_gpu[col]  = X_test_gpu[col].astype(np.float32)\n",
    "\n",
    "    # Build & train GPU SVM\n",
    "    svm_gpu = cuSVC(\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    svm_gpu.fit(X_train_gpu, y_train_gpu)\n",
    "\n",
    "    # Predict + score\n",
    "    y_pred_gpu  = svm_gpu.predict(X_test_gpu)\n",
    "    y_score_gpu = svm_gpu.decision_function(X_test_gpu)\n",
    "\n",
    "    # Back to CPU for reporting\n",
    "    y_true  = y_test_gpu.to_numpy()\n",
    "    y_pred  = y_pred_gpu.to_numpy()\n",
    "    y_score = y_score_gpu.to_numpy()\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"SVM (cuML / GPU)\")\n",
    "    print(\"==============================\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"ROC-AUC (sklearn on CPU, score):\", roc_auc_score(y_true, y_score))\n",
    "    print(\"ROC-AUC (cuML on GPU, score):\", float(cuml_roc_auc_score(y_test_gpu, y_score_gpu)))\n",
    "\n",
    "else:\n",
    "    # -------------------------\n",
    "    # CPU fallback (sklearn)\n",
    "    # -------------------------\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"SVM (sklearn / CPU) – GPU not available\")\n",
    "    print(\"==============================\")\n",
    "    print(\"Reason:\", gpu_import_error)\n",
    "    print(\"Tip: To use GPU you must install RAPIDS (cudf/cuml) with a CUDA-matching environment.\\n\")\n",
    "\n",
    "    Xtr = to_numpy(X_train).astype(np.float32, copy=False)\n",
    "    Xte = to_numpy(X_test).astype(np.float32, copy=False)\n",
    "    ytr = to_numpy(y_train)\n",
    "    yte = to_numpy(y_test)\n",
    "\n",
    "    svm_cpu = SVC(\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    svm_cpu.fit(Xtr, ytr)\n",
    "\n",
    "    y_pred = svm_cpu.predict(Xte)\n",
    "\n",
    "    # decision_function is best for ROC-AUC in SVM\n",
    "    y_score = svm_cpu.decision_function(Xte)\n",
    "\n",
    "    print(classification_report(yte, y_pred))\n",
    "    print(f\"ROC-AUC (score): {roc_auc_score(yte, y_score):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0de4aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "MODEL: Gradient Boosting (Recall>=0.75, max Precision)\n",
      "======================================================\n",
      "Chosen threshold:        0.192498\n",
      "Precision at threshold:  0.372\n",
      "Recall at threshold:     0.755\n",
      "ROC-AUC:                 0.7925\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.911     0.661     0.766      8594\n",
      "           1      0.372     0.755     0.498      2281\n",
      "\n",
      "    accuracy                          0.681     10875\n",
      "   macro avg      0.641     0.708     0.632     10875\n",
      "weighted avg      0.798     0.681     0.710     10875\n",
      "\n",
      "Confusion matrix:\n",
      "[[5681 2913]\n",
      " [ 558 1723]]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Gradient Boosting Classifier\n",
    "# =========================\n",
    "\n",
    "# 1) Build model\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) Train\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# 3) Predict probabilities\n",
    "y_proba = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 4) ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# 5) Precision–Recall curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# thr shorter by 1\n",
    "prec_thr = prec[1:]\n",
    "rec_thr  = rec[1:]\n",
    "\n",
    "# 6) Choose threshold: Recall >= 0.75, maximize Precision\n",
    "target_recall = 0.75\n",
    "valid = np.where(rec_thr >= target_recall)[0]\n",
    "\n",
    "print(\"======================================================\")\n",
    "print(\"MODEL: Gradient Boosting (Recall>=0.75, max Precision)\")\n",
    "print(\"======================================================\")\n",
    "\n",
    "if len(valid) == 0:\n",
    "    print(f\"No threshold achieves recall >= {target_recall}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "else:\n",
    "    best_idx = valid[np.argmax(prec_thr[valid])]\n",
    "    best_thr = thr[best_idx]\n",
    "\n",
    "    y_pred = (y_proba >= best_thr).astype(int)\n",
    "\n",
    "    print(f\"Chosen threshold:        {best_thr:.6f}\")\n",
    "    print(f\"Precision at threshold:  {prec_thr[best_idx]:.3f}\")\n",
    "    print(f\"Recall at threshold:     {rec_thr[best_idx]:.3f}\")\n",
    "    print(f\"ROC-AUC:                 {roc_auc:.4f}\\n\")\n",
    "\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c8bc810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "KNN Classifier (Recall ≥ 0.75)\n",
      "==============================\n",
      "Chosen threshold: 0.16024021906998098\n",
      "Precision: 0.286 | Recall: 0.750\n",
      "ROC-AUC: 0.6859\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.50      0.64      8594\n",
      "           1       0.29      0.75      0.41      2281\n",
      "\n",
      "    accuracy                           0.55     10875\n",
      "   macro avg       0.58      0.63      0.53     10875\n",
      "weighted avg       0.76      0.55      0.59     10875\n",
      "\n",
      "Confusion matrix:\n",
      "[[4317 4277]\n",
      " [ 570 1711]]\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# KNN Classifier\n",
    "# =========================\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=25,\n",
    "    weights=\"distance\",\n",
    "    metric=\"minkowski\"\n",
    ")\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# הסתברויות\n",
    "y_proba = knn.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# Precision–Recall curve\n",
    "prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
    "prec_thr, rec_thr = prec[1:], rec[1:]\n",
    "\n",
    "# יעד Recall\n",
    "target_recall = 0.75\n",
    "valid = np.where(rec_thr >= target_recall)[0]\n",
    "\n",
    "if len(valid) == 0:\n",
    "    print(\"KNN – No threshold achieves recall ≥ 0.75\")\n",
    "else:\n",
    "    best_idx = valid[np.argmax(prec_thr[valid])]\n",
    "    best_thr = thr[best_idx]\n",
    "    y_pred = (y_proba >= best_thr).astype(int)\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"KNN Classifier (Recall ≥ 0.75)\")\n",
    "    print(\"==============================\")\n",
    "    print(\"Chosen threshold:\", best_thr)\n",
    "    print(f\"Precision: {prec_thr[best_idx]:.3f} | Recall: {rec_thr[best_idx]:.3f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7278c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6693816c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
